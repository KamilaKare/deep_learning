{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "1#\n",
    "df=pd.read_csv('C:/Users/Admin/Desktop/AI&DS/TwitterHate.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Get the tweets into a list for easy text cleanup and manipulation.\n",
    "tweet=[df.iloc[i,2] for i in range(df.shape[0])]\n",
    "len(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Cleaning up\n",
    "def clean(twe):\n",
    "    A=twe.lower()\n",
    "    A=re.sub(r\"@\\S+\", \"\", A)\n",
    "    A=re.sub(r\"http\\S+\", \"\", A)\n",
    "    A=re.sub(r\"#\",\"\",A)\n",
    "    A=re.sub(r'\\b\\w{,1}\\b', '', A) \n",
    "    return A\n",
    "\n",
    "tweet=[clean(sen) for sen in tweet]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tknzr=TweetTokenizer()\n",
    "tweet_token=[tknzr.tokenize(text) for text in tweet]\n",
    "\n",
    "stop_word=set(stopwords.words('english'))\n",
    "tweet_token2=[]\n",
    "for tex in tweet_token:\n",
    "    out=[i for i in set(tex) if not i in stop_word]\n",
    "    tweet_token2.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dysfunction',\n",
       "  'father',\n",
       "  'drags',\n",
       "  'run',\n",
       "  'selfish',\n",
       "  '.',\n",
       "  'dysfunctional',\n",
       "  'kids'],\n",
       " ['offer',\n",
       "  'use',\n",
       "  'getthanked',\n",
       "  'pdx',\n",
       "  '.',\n",
       "  'vans',\n",
       "  'disapointed',\n",
       "  'credit',\n",
       "  'lyft',\n",
       "  'wheelchair',\n",
       "  'thanks',\n",
       "  'cause',\n",
       "  \"'\"]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_token2[0:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 we remove terms with a length of 1.\n",
    "tweet_token3=[]\n",
    "for tex in tweet_token2:\n",
    "    out=[i for i in tex if len(i)>1]\n",
    "    tweet_token3.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dysfunction', 'father', 'drags', 'run', 'selfish', 'dysfunctional', 'kids']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_token3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most common terms with their frequences are\n",
      "love 2526\n",
      "... 2520\n",
      "day 2118\n",
      "happy 1587\n",
      "time 1099\n",
      "today 1059\n",
      "like 1037\n",
      "life 1037\n",
      "positive 913\n",
      "new 912\n"
     ]
    }
   ],
   "source": [
    "#5. Check out the top terms in the tweets:\n",
    "#5.1 First, get all the tokenized terms into one large list.\n",
    "tweet_liste=[]\n",
    "for text in tweet_token3:\n",
    "    for i in text:\n",
    "        tweet_liste.append(i)\n",
    "\n",
    "\n",
    "#5.2 Use the counter and find the 10 most common terms.\n",
    "dico={}\n",
    "for i in tweet_liste:\n",
    "    a=dico.get(i,0)\n",
    "    dico[i]=a+1\n",
    "\n",
    "print('The 10 most common terms with their frequences are')\n",
    "for i in range(10):\n",
    "    max_key = max(dico, key=dico.get)\n",
    "    print(max_key, dico[max_key])\n",
    "    del(dico[max_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.Data formatting for predictive modeling:\n",
    "#6.1 Join the tokens back to form strings. \n",
    "tweet2=[(' ').join(twe)  for twe in tweet_token3]\n",
    "\n",
    "\n",
    "#6.2 Assign x and y.\n",
    "X=tweet2; y=df['label']\n",
    "\n",
    "#Perform train_test_split using sklearn.\n",
    "x_train,x_test, y_train,y_test=train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Weâ€™ll use TF-IDF values for the terms as a feature to get into a vector space model.\n",
    "tf=TfidfVectorizer(decode_error='ignore',lowercase=False,max_features=5000)\n",
    "\n",
    "x_traintf=tf.fit_transform(x_train)\n",
    "\n",
    "x_testtf=tf.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.Model building: Ordinary Logistic Regression\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "#Fit into  the train data.\n",
    "clf.fit(x_traintf,y_train)\n",
    "\n",
    "#Make predictions for the train and the test set.\n",
    "clf.predict(x_traintf)\n",
    "clf.predict(x_testtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9556964665637645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98     22269\n",
      "          1       0.96      0.39      0.56      1702\n",
      "\n",
      "avg / total       0.96      0.96      0.95     23971\n",
      "\n",
      "the recall is high however the model focuses a lot on 0 class\n"
     ]
    }
   ],
   "source": [
    "#9. Model evaluation: Accuracy, recall, and f_1 score.\n",
    "\n",
    "#Report the accuracy on the train set.\n",
    "score = clf.score(x_traintf, y_train)\n",
    "print('The accuracy is', score)\n",
    "\n",
    "#Report the recall on the train set: decent, high, or low.\n",
    "#Get the f1 score on the train set.\n",
    "y_pred=clf.predict(x_traintf)\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('the recall is high however the model focuses a lot on 0 class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Adjust the appropriate class in the LogisticRegression model.\n",
    "weights = {0:1.0, 1:10.0}\n",
    "clf2 = LogisticRegression(solver='lbfgs', class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9632472571023319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98     22269\n",
      "          1       0.67      0.97      0.79      1702\n",
      "\n",
      "avg / total       0.97      0.96      0.97     23971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#11. Train again with the adjustment and evaluate.\n",
    "#Evaluate the predictions on the train set: accuracy, recall, and f_1 score.\n",
    "clf2.fit(x_traintf,y_train)\n",
    "y_pred2=clf2.predict(x_traintf)\n",
    "\n",
    "score = clf2.score(x_traintf, y_train)\n",
    "print(score)\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can provide best weights using grid search\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "balance = [{0:1,1:10}, {0:1,1:100}, {0:1,1:1}, {0:10,1:1}, {0:100,1:1}]\n",
    "param_grid = dict(class_weight=balance)\n",
    "cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=1, random_state=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='recall')\n",
    "grid_result = grid.fit(x_traintf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719241658004988"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. Regularization and Hyperparameter tuning:\n",
    "\n",
    "parameters = {'penalty':('l1', 'l2'), 'C':[1, 10]}\n",
    "clf = LogisticRegression(random_state=0,class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13 Find the parameters with the best recall in cross validation.\n",
    "cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=1, random_state=1)\n",
    "grid = GridSearchCV(estimator=clf, param_grid=parameters, n_jobs=-1, cv=cv, scoring='recall')\n",
    "\n",
    "grid_result = grid.fit(x_traintf,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.783199 using {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#14  best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6501063696658741\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.67      0.78      7451\n",
      "          1       0.08      0.40      0.13       540\n",
      "\n",
      "avg / total       0.88      0.65      0.74      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#15 Predict and evaluate using the best estimator.\n",
    "clf = LogisticRegression(random_state=0,class_weight={0:1.0, 1:100.0},penalty='l2',C=1)\n",
    "clf.fit(x_traintf,y_train)\n",
    "y_pred2=clf.predict(x_testtf)\n",
    "\n",
    "score = clf.score(x_testtf, y_test)\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
